{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.util import img_as_float32, img_as_ubyte\n",
    "\n",
    "from models import PAT\n",
    "from ext_utils import find_good_matching_points, _project_mesh_grid_to_indices_cube, move_pixel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load source images\n",
    "data_folder = '../data/quad_camera_sample/'\n",
    "quad = [imread(os.path.join(data_folder, fn)) for fn in \\\n",
    "        ['cam4_w_exp150.png', 'cam1_r_exp500.png', 'cam2_g_exp300.png', 'cam3_b_exp800.png']]\n",
    "\n",
    "# precrop and scale low-res images for better inference\n",
    "hr = quad[0]\n",
    "h, w = hr.shape\n",
    "lrs = [cv.resize(img[h//5:-h//5, w//5:-w//5], (w,h), interpolation=cv.INTER_CUBIC) \\\n",
    "       for img in quad[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show source images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "for k in range(3):\n",
    "    _tmp_img = np.zeros((h,w,3), dtype=np.uint8)\n",
    "    _tmp_img[..., k] = lrs[k]\n",
    "    axes.flatten()[k].imshow(_tmp_img)\n",
    "axes.flatten()[-1].imshow(hr, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network\n",
    "net = PAT(1, in_channel=1, num_input=4).to('cuda')\n",
    "net = nn.DataParallel(net)\n",
    "net.eval()\n",
    "cudnn.benchmark = True\n",
    "pretrained_dict = torch.load('./weights/quad_input_weights.pth.tar')\n",
    "net.load_state_dict(pretrained_dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get query matrix\n",
    "img_left = torch.from_numpy(img_as_float32(hr)[..., np.newaxis].transpose((2, 0, 1))).unsqueeze(0).to('cuda')\n",
    "with torch.no_grad():\n",
    "    x_left = net.module.init_feature(img_left)\n",
    "    buffer_left = net.module.pam.rb(x_left)\n",
    "    Q = net.module.pam.b1(buffer_left)\n",
    "    \n",
    "    # prepare fused feature\n",
    "    fused_feature = torch.zeros((1, 256, h, w)).float().to('cuda')\n",
    "    fused_feature[:,-64:,:,:,] = x_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention receptive field and block parameters\n",
    "\n",
    "hw = 8 # half window width\n",
    "s = 1  # strides\n",
    "\n",
    "ph, pw = 200, 320 # patch width\n",
    "m, n = np.ceil(h/ph).astype(int), np.ceil(w/pw).astype(int)\n",
    "i_list, j_list = np.meshgrid(np.arange(m), np.arange(n), indexing='ij')\n",
    "ij_list = np.stack([i_list, j_list], axis=-1).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process one image at a time\n",
    "for k in trange(3): \n",
    "    # find rough correspondence with SIFT\n",
    "    pts1, pts2 = find_good_matching_points(lrs[k], hr)\n",
    "    M_h2l, _ = cv.findHomography(pts2.reshape(-1,1,2),\n",
    "                                 pts1.reshape(-1,1,2),\n",
    "                                 cv.RANSAC, 5.0)\n",
    "    yys, xxs = _project_mesh_grid_to_indices_cube((w, h), (w, h), M_h2l, hw, s) # original PAT abuse x/y \n",
    "                                                                                # for first/second index\n",
    "    # get key and value matrices\n",
    "    img_right = torch.from_numpy(img_as_float32(lrs[k])[..., np.newaxis].transpose((2, 0, 1))).unsqueeze(0).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        x_right = net.module.init_feature(img_right)\n",
    "        buffer_right = net.module.pam.rb(x_right)\n",
    "        K = net.module.pam.b2s[k](buffer_right)\n",
    "        V = net.module.pam.b3s[k](buffer_right)\n",
    "        # apply attention block by block\n",
    "        for (i, j) in tqdm(ij_list):\n",
    "            xl, xu, yl, yu = i*ph, i*ph+ph, j*pw, j*pw+pw\n",
    "            Q_ = Q[:, :, xl:xu,yl:yu].contiguous()\n",
    "            Po = (torch.from_numpy(xxs[xl:xu, yl:yu][np.newaxis]), \n",
    "                  torch.from_numpy(yys[xl:xu, yl:yu][np.newaxis]))\n",
    "            buffer, _ = net.module.pam.fe_pam(Q_, K, V, Po, False)\n",
    "            fused_feature[:, k*64:(k+1)*64, xl:xu, yl:yu] = buffer\n",
    "            \n",
    "with torch.no_grad():\n",
    "    out = net.module.pam.fusion(fused_feature)\n",
    "    out = net.module.upscale(out)\n",
    "    \n",
    "pred = out.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "del yys, xxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white balance via normalize with channel inputs\n",
    "for k, lr in enumerate(lrs):\n",
    "    u = np.mean(img_as_float32(lr).flatten())\n",
    "    s = np.std(img_as_float32(lr).flatten())\n",
    "    pred[...,k] = move_pixel_value(pred[...,k],u,s)\n",
    "    \n",
    "pred = np.clip(pred,0,1)\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = os.path.join(\"../results\", \"pat_quad_camera\")\n",
    "if not os.path.exists(subfolder):\n",
    "    os.mkdir(subfolder)\n",
    "\n",
    "for k, lr in enumerate(lrs):\n",
    "    _tmp_img = np.zeros((h,w,3), dtype=np.uint8)\n",
    "    _tmp_img[..., k] = lr\n",
    "    imsave(os.path.join(subfolder, 'lr_{}.png'.format(k)), _tmp_img, check_contrast=False)\n",
    "imsave(os.path.join(subfolder, 'hr.png'), hr)\n",
    "imsave(os.path.join(subfolder, 'pred.png'), img_as_ubyte(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plvis",
   "language": "python",
   "name": "plvis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
